{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Getting a set of words from different languages\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Libraries\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "**Spacy**: To get words from different languages, we use the Spacy library.\n",
    "\n",
    "**Pickle**: We use this library to output words."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "import pickle"
   ],
   "metadata": {
    "id": "V4mAXRFkKzyv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "def save_words(model):\n",
    "  nlp = spacy.load(model)\n",
    "  list_words=list(nlp.vocab.strings)\n",
    "  list_alpha_words=[]\n",
    "  for i in list_words:\n",
    "    if i.isalpha():\n",
    "      list_alpha_words.append(i)\n",
    "  return set(list_alpha_words)"
   ],
   "metadata": {
    "id": "W8Olg95am7f_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Download spatial models to access words in different languages. \n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### Languages\n",
    "\n",
    "- `english` (en_core_web_sm)\n",
    "- `spanish` (es_core_news_sm)\n",
    "- `swedish` (sv_core_news_sm)\n",
    "- `russian` (ru_core_news_sm)\n",
    "- `french` (fr_core_news_sm)\n",
    "- `german` (de_core_news_sm)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m spacy download fr_core_news_sm\n",
    "!python -m spacy download sv_core_news_sm\n",
    "!python -m spacy download es_core_news_sm\n",
    "!python -m spacy download ru_core_news_sm\n",
    "!python -m spacy download de_core_news_sm\n",
    "!python -m spacy download en_core_web_sm"
   ],
   "metadata": {
    "id": "BLylZOSJ1e3U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To extract words from spatial models, we give them to the `save_words` function to extract these words for us."
  },
  {
   "cell_type": "code",
   "source": [
    "english_words=save_words('en_core_web_sm')\n",
    "swedish_words=save_words('sv_core_news_sm')\n",
    "french_words=save_words ('fr_core_news_sm')\n",
    "german_words=save_words ('de_core_news_sm')\n",
    "spanish_words=save_words('es_core_news_sm')\n",
    "russian_words=save_words('ru_core_news_sm')\n"
   ],
   "metadata": {
    "id": "_NX1oSYSK1X3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To output words, we use the `Pickle` library and the `dump()` method."
  },
  {
   "cell_type": "code",
   "source": [
    "pickle.dump(english_words,open('english_words.sug','wb'))\n",
    "pickle.dump(swedish_words,open('swedish_words.sug','wb'))\n",
    "pickle.dump(french_words,open('french_words.sug','wb'))\n",
    "pickle.dump(german_words,open('german_words.sug','wb'))\n",
    "pickle.dump(spanish_words,open('spanish_words.sug','wb'))\n",
    "pickle.dump(russian_words,open('russian_words.sug','wb'))\n"
   ],
   "metadata": {
    "id": "ZNi_mrrHK2bS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Hint**: After getting the output of the words, we need to place them in the following path.\n",
    "\n",
    "- `PrediText/datasets/auto_word_complete`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
